<div style='height:450px;overflow:auto'>

    <p style='font-weight:bold;font-size:16px'>简介：</p>

    <p>DeepSeek Coder由一系列代码语言模型组成，每个模型都是在2T tokens上从头开始训练的，其中87%的代码和13%的中英文自然语言生成。6.7B参数量的模型通过使用16K的窗口大小和额外的填空任务在项目级代码语料库上进行预训练，以支持项目级代码完成和填充。在编码功能方面，DeepSeek Coder在多种编程语言和各种基准测试的开源代码模型中实现了最先进的性能。</p>

    <p>1. 海量训练数据：在2T tokens上从头开始训练的，其中87%的代码数据和13%的中英文语料数据。</p>

    <p>2. 高度灵活和可扩展性：能够通过模型压缩提供不同参数量的模型以满足不同实际场景需求。</p>

    <p>3. 卓越的模型性能：在HumanEval，MultiPL-E，MBPP，DS-1000和APPS基准测试的公开可用代码模型中具有最先进的性能。</p>

    <p>4. 高级代码补全能力：窗口大小为16K，支持填空任务，支持项目级代码补全和填空任务。</p>

</div>