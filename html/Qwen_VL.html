<div style='height:450px;overflow:auto'>

    <p style='font-weight:bold;font-size:16px'>简介：</p>

    <p>Qwen-VL 是阿里云研发的大规模视觉语言模型（Large Vision Language Model, LVLM）。Qwen-VL 可以以图像、文本、检测框作为输入，并以文本和检测框作为输出。Qwen-VL 系列模型的特点包括：</p>

    <p>1. 强大的性能：在四大类多模态任务的标准英文测评中（Zero-shot Captioning/VQA/DocVQA/Grounding）上，均取得同等通用模型大小下最好效果；</p>

    <p>2. 多语言对话模型：天然支持英文、中文等多语言对话，端到端支持图片里中英双语的长文本识别；</p>

    <p>3. 多图交错对话：支持多图输入和比较，指定图片问答，多图文学创作等；</p>

    <p>4. 首个支持中文开放域定位的通用模型：通过中文开放域语言表达进行检测框标注；</p>

    <p>5. 细粒度识别和理解：相比于目前其它开源LVLM使用的224分辨率，Qwen-VL是首个开源的448分辨率的LVLM模型。更高分辨率可以提升细粒度的文字识别、文档问答和检测框标注。</p>

</div>